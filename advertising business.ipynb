{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Advertising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Business Context:** \n",
        "\n",
        "Retail company, \"Fashion Haven,\" operates multiple stores in different cities. The company invests in advertising campaigns to promote its latest collections through various media sources like TV, Newspaper, and Radio. They want to understand the impact of each media source on their sales revenue to optimize their advertising strategy and improve overall business performance.\n",
        "\n",
        "Currently, Fashion Haven lacks an effective method to predict the sales revenue generated from their advertising efforts accurately. As a result, they struggle to allocate their advertising budget optimally across different media channels, leading to sub optimal returns on investment and inefficient resource allocation.\n",
        "\n",
        "To address this business problem, Fashion Haven has collected historical data containing information on various advertising campaigns (TV, Newspaper, Radio) and their corresponding sales revenue across their different store locations. The goal is to build a robust predictive model that accurately estimates the sales revenue based on the media sources' advertising budgets, helping the company make data-driven decisions and drive business growth.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Dataset Description:\n",
        "\n",
        "The data contains the different attributes of the advertising business. The detailed data dictionary is given below.\n",
        "\n",
        "* TV: Expenditure on media resource- TV \n",
        "* Radio: Expenditure on media resource- Radio \n",
        "* NewsPaper: Expenditure on media resource- Newspaper \n",
        "* Sales: Target Column - Amount of Sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mlflow in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (2.13.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (8.1.3)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (6.1.2)\n",
            "Requirement already satisfied: pandas<3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.1.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (6.0)\n",
            "Requirement already satisfied: entrypoints<1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11; platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (2.11.2)\n",
            "Requirement already satisfied: numpy<2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle<4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.6.0)\n",
            "Requirement already satisfied: querystring-parser<2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (5.3.0)\n",
            "Requirement already satisfied: scipy<2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.5.3)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (3.4.3)\n",
            "Requirement already satisfied: Flask<4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (2.3.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.13.1)\n",
            "Requirement already satisfied: pytz<2025 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (2022.5)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (0.4.4)\n",
            "Requirement already satisfied: packaging<25 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (23.0)\n",
            "Requirement already satisfied: matplotlib<4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (3.2.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: gunicorn<23; platform_system != \"Windows\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (20.1.0)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (6.6.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (2.0.30)\n",
            "Requirement already satisfied: scikit-learn<2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (0.22.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: graphene<4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (3.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mlflow) (3.1.31)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from docker<8,>=4.0.0->mlflow) (1.26.16)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from docker<8,>=4.0.0->mlflow) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas<3->mlflow) (2.8.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Jinja2<4,>=2.11; platform_system != \"Windows\"->mlflow) (2.0.1)\n",
            "Requirement already satisfied: six in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (3.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.17.3->mlflow) (2022.9.24)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Flask<4->mlflow) (1.6.2)\n",
            "Requirement already satisfied: Werkzeug>=2.3.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Flask<4->mlflow) (2.3.4)\n",
            "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (5.12.0)\n",
            "Requirement already satisfied: Mako in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from alembic!=1.10.0,<2->mlflow) (4.6.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib<4->mlflow) (3.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow) (0.46b0)\n",
            "Requirement already satisfied: setuptools>=3.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gunicorn<23; platform_system != \"Windows\"->mlflow) (65.6.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.12.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\"))))) in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from graphene<4->mlflow) (9.0.1)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from graphene<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.10)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow) (1.12.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Connect to the workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1718495282994
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Handle to the workspace\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "# Authentication package\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml import command\n",
        "from azure.ai.ml.sweep import Choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "From VMs within the Azure ML workspace, the default Azure credentials are inherited. However, interactive browser credentials could be used to authenticate an Azure account to the Azure ML workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1718495286602
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "credential = DefaultAzureCredential(exclude_interactive_browser_credential=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1718495290570
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Get a handle to the workspace\n",
        "ml_client = MLClient(\n",
        "    credential=credential,\n",
        "    subscription_id=\"4322d79c-475f-471d-bd6d-52528e4d32ee\", # Assigned subscription ID \n",
        "    resource_group_name=\"tasnim_rg\", # Assigned Resource Group \n",
        "    workspace_name=\"maycohortmlops\", #Assigned workspace name\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create a compute resource to run the job\n",
        "Azure Machine Learning needs a compute resource to run a job. This resource can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark.\n",
        "\n",
        "A basic compute cluster is need for this task; thus, picking a Standard_D2s_v3 model with 2 CPU cores and 8 GB RAM to create an Azure Machine Learning compute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1718495331429
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new cpu compute target...\n",
            "AMLCompute with name cpu-cluster-MP1 is created, the compute size is STANDARD_D2s_V3\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml.entities import AmlCompute\n",
        "\n",
        "# Name assigned to the compute cluster\n",
        "cpu_compute_target = \"cpu-cluster-MP1\"\n",
        "\n",
        "try:\n",
        "    # let's see if the compute target already exists\n",
        "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
        "    print(\n",
        "        f\"You already have a cluster named {cpu_compute_target}, reuse it as is.\"\n",
        "    )\n",
        "\n",
        "except Exception:\n",
        "    print(\"Creating a new cpu compute target...\")\n",
        "\n",
        "    # Let's create the Azure ML compute object with the intended parameters\n",
        "    cpu_cluster = AmlCompute(\n",
        "        name=cpu_compute_target,\n",
        "        # Azure ML Compute is the on-demand VM service\n",
        "        type=\"amlcompute\",\n",
        "        # VM Family\n",
        "        size=\"STANDARD_D2s_V3\",\n",
        "        # Minimum running nodes when there is no job running\n",
        "        min_instances=0,\n",
        "        # Nodes in cluster\n",
        "        max_instances=1,\n",
        "        # How many seconds will the node running after the job termination\n",
        "        idle_time_before_scale_down=180,\n",
        "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
        "        tier=\"Dedicated\",\n",
        "    )\n",
        "\n",
        "    # Now, we pass the object to MLClient's create_or_update method\n",
        "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster).result()\n",
        "\n",
        "print(\n",
        "    f\"AMLCompute with name {cpu_cluster.name} is created, the compute size is {cpu_cluster.size}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Upload the dataset on Blob Storage as Data Asset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Let's explore the process of registering an external dataset as a data asset in the Azure ML environment. In this scenario, we will copy a local dataset to Azure blob storage and then proceed to register the file as a data asset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1718495352185
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "local_data_path = 'data/advertising_raw.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Azure provides a convenient way to manage datasets using a feature called data assets. Data assets are built on top of cloud fsspec (file system specification) and offer additional functionalities such as tracking and versioning of different datasets.\n",
        "\n",
        "Unlike the actual data files stored in blob storage, data assets act as a lightweight wrapper that includes valuable metadata without incurring any extra cost. This allows us to register a dataset and easily update its version whenever new data is added."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1718495360924
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_asset = Data(\n",
        "    path=local_data_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"A data set containing the information on various advertising campaigns (TV, Newspaper, Radio) and their corresponding sales revenue\",\n",
        "    name=\"advertising-data\",\n",
        "    version=\"1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1718495369148
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading advertising_raw.csv\u001b[32m (< 1 MB): 100%|██████████| 4.06k/4.06k [00:00<00:00, 317kB/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data({'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'advertising-data', 'description': 'A data set containing the information on various advertising campaigns (TV, Newspaper, Radio) and their corresponding sales revenue', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/data/advertising-data/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurekernelmlops2024/code/Users/niger.tasnim21/Milestoneproject1', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd8a4233d90>, 'serialize': <msrest.serialization.Serializer object at 0x7fd8a4233220>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops/datastores/workspaceblobstore/paths/LocalUpload/d76b5403a3179fcd4ea0e1d4ebd5e602/advertising_raw.csv', 'datastore': None})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.data.create_or_update(data_asset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Checking for registered data assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1718495511505
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated_diamonds_data\n",
            "Updated_diamind_data\n",
            "advertising-data\n"
          ]
        }
      ],
      "source": [
        "for registered_data in ml_client.data.list():\n",
        "    print(registered_data.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create a processing script to perform the data preprocessing job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Creating a folder \"src\" to store the processing script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1718495518510
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "train_src_dir = \"./src\"\n",
        "os.makedirs(train_src_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Configure the processing job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./src/pre_process.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/pre_process.py\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import azureml.core\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.core import Workspace\n",
        "\n",
        "def main():\n",
        " \"\"\"Main function of the script.\"\"\"\n",
        "\n",
        " # input and output arguments\n",
        " parser = argparse.ArgumentParser()\n",
        " parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
        " parser.add_argument(\"--output\", type=str, help=\"path to output data\")\n",
        " args = parser.parse_args()\n",
        " \n",
        " # Start Logging\n",
        " mlflow.start_run()\n",
        "\n",
        " # enable autologging\n",
        " mlflow.sklearn.autolog()\n",
        "\n",
        " ###################\n",
        " #<prepare the data>\n",
        " ###################\n",
        " \n",
        " print(\"input data:\", args.data)\n",
        " \n",
        " data = pd.read_csv(args.data)\n",
        "\n",
        "\n",
        " ###################\n",
        " #<processing>\n",
        " ###################\n",
        "\n",
        " # Separate  numerical features\n",
        " numerical_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        " # Apply data scaling to numerical columns\n",
        " scaler = StandardScaler()\n",
        " data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        " # Exporting processed data to local\n",
        " processed_data_path = os.path.join(args.output, 'advertising_sales_processed_data.csv')\n",
        " data.to_csv(processed_data_path, index=False)\n",
        "\n",
        " # Stop Logging\n",
        " mlflow.end_run()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        " main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Run the Processing job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1718495635347
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "datastore_path=\"azureml://datastores/workspaceblobstore/paths/advertising_sales_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1718495650064
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "my_job_inputs = {\n",
        "    \"input_data\": Input(type=AssetTypes.URI_FILE, \n",
        "                        path=\"azureml:advertising-data:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"output_datastore\": Output(type=AssetTypes.URI_FOLDER,\n",
        "                               path=datastore_path)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Configure the Processing job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1718495734597
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "job = command(\n",
        "    code=\"./src/\", # location of source code\n",
        "    command=\"python pre_process.py --data ${{inputs.input_data}} --output ${{outputs.output_datastore}}\",\n",
        "    inputs= my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"cpu-cluster-MP1\",\n",
        "    experiment_name=\"12-06-2024-advertising-data-preprocessing-001\",\n",
        "    display_name=\"advertising_data_processing-001\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "##### Submit the training job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1718495747313
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "\u001b[32mUploading src (0.0 MBs): 100%|██████████| 1334/1334 [00:00<00:00, 31039.27it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>12-06-2024-advertising-data-preprocessing-001</td><td>ivory_gyro_skyswr4s5l</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/ivory_gyro_skyswr4s5l?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops&amp;tid=c2d0311d-e2d5-4ed2-8e3d-2ce531ceb5df\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "Command({'parameters': {}, 'init': False, 'name': 'ivory_gyro_skyswr4s5l', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster-MP1', 'ContentSnapshotId': '5f2470f6-7763-4a0f-85b4-18ca5d26945d'}, 'print_as_yaml': True, 'id': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/jobs/ivory_gyro_skyswr4s5l', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurekernelmlops2024/code/Users/niger.tasnim21/Milestoneproject1', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd89d5cb820>, 'serialize': <msrest.serialization.Serializer object at 0x7fd89d5cbd00>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'advertising_data_processing-001', 'experiment_name': '12-06-2024-advertising-data-preprocessing-001', 'compute': 'cpu-cluster-MP1', 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/ivory_gyro_skyswr4s5l?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops&tid=c2d0311d-e2d5-4ed2-8e3d-2ce531ceb5df', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'input_data': {'type': 'uri_file', 'path': 'advertising-data:1', 'mode': 'ro_mount'}}, 'job_outputs': {'output_datastore': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/advertising_sales_data', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.ivory_gyro_skyswr4s5l', 'mode': 'rw_mount'}}, 'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fd89d5cbf10>}, 'outputs': {'output_datastore': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fd89d5cbfd0>, 'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fd89d5cbf40>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'ivory_gyro_skyswr4s5l', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd89d5cb820>, 'serialize': <msrest.serialization.Serializer object at 0x7fd89d5cbdc0>, 'command': 'python pre_process.py --data ${{inputs.input_data}} --output ${{outputs.output_datastore}}', 'code': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/codes/9ef591cf-bde8-40bf-8140-e1bf28f30c97/versions/1', 'environment_variables': {}, 'environment': 'azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'advertising_data_processing-001', 'is_deterministic': True, 'inputs': {'input_data': {'type': 'uri_file', 'path': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/data/advertising-data/versions/1', 'mode': 'ro_mount'}}, 'outputs': {'output_datastore': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/advertising_sales_data', 'mode': 'rw_mount'}, 'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.ivory_gyro_skyswr4s5l', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/ivory_gyro_skyswr4s5l?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops&tid=c2d0311d-e2d5-4ed2-8e3d-2ce531ceb5df', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd89d5cb820>}, 'instance_id': 'b3b1a664-2426-48ea-abaa-8ae3dc7c2c80', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.create_or_update(job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create a training script to perform the training job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./src/main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/main.py\n",
        "\n",
        "import mlflow\n",
        "import argparse\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "mlflow.start_run()\n",
        "\n",
        "def main():\n",
        "\n",
        " parser = argparse.ArgumentParser()\n",
        " parser.add_argument(\"--data\", type=str, help=\"path to train data\")\n",
        " parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
        " parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
        "\n",
        " args = parser.parse_args()\n",
        "\n",
        " df = pd.read_csv(args.data)\n",
        " \n",
        " target = 'Sales'\n",
        " numeric_features = ['TV','Radio', 'Newspaper']\n",
        " #categorical_features = []\n",
        "\n",
        " X = df.drop([target], axis=1)\n",
        " y = df[target]\n",
        "\n",
        " X_train, X_test, y_train, y_test = train_test_split(\n",
        " X, y, test_size=0.2, random_state=42\n",
        " )\n",
        "\n",
        " model_gbr = GradientBoostingRegressor(\n",
        " n_estimators=args.n_estimators,\n",
        " learning_rate=args.learning_rate\n",
        " )\n",
        "\n",
        " model_pipeline = make_pipeline(model_gbr)\n",
        "\n",
        " model_pipeline.fit(X_train, y_train)\n",
        " \n",
        " rsq = model_pipeline.score(X_test, y_test)\n",
        "\n",
        " mlflow.log_metric(\"RSquared\", float(rsq))\n",
        "\n",
        " print(\"Registering model pipeline\")\n",
        "\n",
        " mlflow.sklearn.log_model(\n",
        " sk_model=model_pipeline,\n",
        " registered_model_name=\"gbr-adv-sales-predictor\",\n",
        " artifact_path=\"gbr-adv-sales-predictor\"\n",
        " )\n",
        "\n",
        " mlflow.end_run()\n",
        "\n",
        "if __name__ == '__main__':\n",
        " main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Configure the training job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1718496174766
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_job = command(\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_file\", path=\"azureml://datastores/workspaceblobstore/paths/advertising_sales_data/advertising_sales_processed_data.csv\")\n",
        "    },\n",
        "    code=\"src/main.py\",\n",
        "    command=\"python main.py --data ${{inputs.data}}\",\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n",
        "    display_name=\"sales-adv-training-001\",\n",
        "    experiment_name=\"12-06-2024-sales-adv-training-001\",\n",
        "    compute= \"cpu-cluster-MP1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Run the training job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1718496182651
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\u001b[32mUploading main.py\u001b[32m (< 1 MB): 0.00B [00:00, ?B/s]\r\u001b[32mUploading main.py\u001b[32m (< 1 MB): 100%|██████████| 1.49k/1.49k [00:00<00:00, 55.7kB/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>12-06-2024-sales-adv-training-001</td><td>blue_diamond_snjt5ns2pp</td><td>command</td><td>Starting</td><td><a href=\"https://ml.azure.com/runs/blue_diamond_snjt5ns2pp?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops&amp;tid=c2d0311d-e2d5-4ed2-8e3d-2ce531ceb5df\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "Command({'parameters': {}, 'init': False, 'name': 'blue_diamond_snjt5ns2pp', 'type': 'command', 'status': 'Starting', 'log_files': None, 'description': None, 'tags': {}, 'properties': {'_azureml.ComputeTargetType': 'amlctrain', '_azureml.ClusterName': 'cpu-cluster-MP1', 'ContentSnapshotId': '8295ad43-41ba-4103-98f2-82d73a291b23'}, 'print_as_yaml': True, 'id': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/jobs/blue_diamond_snjt5ns2pp', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurekernelmlops2024/code/Users/niger.tasnim21/Milestoneproject1', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd89d56db70>, 'serialize': <msrest.serialization.Serializer object at 0x7fd89d56d7e0>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': 'sales-adv-training-001', 'experiment_name': '12-06-2024-sales-adv-training-001', 'compute': 'cpu-cluster-MP1', 'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/blue_diamond_snjt5ns2pp?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops&tid=c2d0311d-e2d5-4ed2-8e3d-2ce531ceb5df', 'type': 'Studio'}}, 'comment': None, 'job_inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/advertising_sales_data/advertising_sales_processed_data.csv', 'mode': 'ro_mount'}}, 'job_outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.blue_diamond_snjt5ns2pp', 'mode': 'rw_mount'}}, 'inputs': {'data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x7fd89d56db10>}, 'outputs': {'default': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x7fd89d56e140>}, 'component': CommandComponent({'intellectual_property': None, 'auto_increment_version': True, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': False, 'auto_delete_setting': None, 'name': 'blue_diamond_snjt5ns2pp', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': PosixPath('.'), 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd89d56db70>, 'serialize': <msrest.serialization.Serializer object at 0x7fd89d56e080>, 'command': 'python main.py --data ${{inputs.data}}', 'code': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/codes/6fb9a5c8-7d47-480d-ae34-845ca0b6ad0d/versions/1', 'environment_variables': {}, 'environment': 'azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest', 'distribution': None, 'resources': None, 'queue_settings': None, 'version': None, 'latest_version': None, 'schema': None, 'type': 'command', 'display_name': 'sales-adv-training-001', 'is_deterministic': True, 'inputs': {'data': {'type': 'uri_file', 'path': 'azureml://datastores/workspaceblobstore/paths/advertising_sales_data/advertising_sales_processed_data.csv', 'mode': 'ro_mount'}}, 'outputs': {'default': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceartifactstore/ExperimentRun/dcid.blue_diamond_snjt5ns2pp', 'mode': 'rw_mount'}}, 'yaml_str': None, 'other_parameter': {'status': 'Starting', 'parameters': {}}, 'additional_includes': [], 'CommandComponent__additional_includes_obj': None}), 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': {'Tracking': {'endpoint': 'azureml://eastus.api.azureml.ms/mlflow/v1.0/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/blue_diamond_snjt5ns2pp?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops&tid=c2d0311d-e2d5-4ed2-8e3d-2ce531ceb5df', 'type': 'Studio'}}, 'status': 'Starting', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fd89d56db70>}, 'instance_id': 'da1dcb2f-0c39-492c-b6df-dc7d89de74b7', 'source': 'BUILDER', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': 'azureml:AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest', 'resources': {'instance_count': 1, 'shm_size': '2g'}, 'queue_settings': None, 'swept': False})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.create_or_update(train_job)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Define the parameter space for hyperparameter tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Further improve the accuracy of model, tune and optimize the model's hyperparameters using Azure Machine Learning's sweep capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1718496393797
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "train_job = command(\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_file\", path=\"azureml://datastores/workspaceblobstore/paths/advertising_sales_data/advertising_sales_processed_data.csv\"),\n",
        "        \"n_estimators\": 100,\n",
        "        \"learning_rate\": 0.1\n",
        "    },\n",
        "    code=\"src/main.py\",\n",
        "    command=\"python main.py --data ${{inputs.data}} --n_estimators ${{inputs.n_estimators}} --learning_rate ${{inputs.learning_rate}}\",\n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n",
        "    compute= \"cpu-cluster-MP1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To tune the model's hyperparameters:\n",
        "\n",
        "    - Define the parameter space in which to search during training.\n",
        "\n",
        "    - Replacing the parameters (n_estimators and mearning_rate) passed to the training job with special inputs from the azure.ml.sweep package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1718496398205
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "job_for_sweep = train_job(\n",
        "    n_estimators=Choice(values=[100, 200, 300, 400]),\n",
        "    learning_rate=Choice(values=[0.001, 0.005, 0.05, 0.1, 0.5])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Configure the sweep job for tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1718496403852
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# sampling_algorithm specifies the search algorithm to use for hyperparameter tuning.\n",
        "# primary_metric specifies the metric to optimize during hyperparameter tuning.\n",
        "# goal specifies whether to maximize or minimize the primary metric.\n",
        "# max_total_trials specifies the maximum number of trials to run during hyperparameter tuning.\n",
        "# max_concurrent_trials specifies the maximum number of trials to run concurrently during hyperparameter tuning.\n",
        "sweep_job = job_for_sweep.sweep(\n",
        "    sampling_algorithm=\"bayesian\",\n",
        "    primary_metric=\"RSquared\",\n",
        "    goal=\"Maximize\",\n",
        "    max_total_trials=6,\n",
        "    max_concurrent_trials=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1718496408760
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "sweep_job.experiment_name = \"13-06-2024-sales_advertising-001\"\n",
        "sweep_job.display_name = \"sales_advertising_tuning-001\"\n",
        "sweep_job.description = \"Run a hyperparameter sweep job for GBR\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Run the sweep job"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now running a sweep job that sweeps over train job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1718496729081
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RunId: dynamic_turtle_j8xh572jcq\n",
            "Web View: https://ml.azure.com/runs/dynamic_turtle_j8xh572jcq?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "[2024-06-16T00:06:58.937427][GENERATOR][INFO]Trying to sample '3' jobs from the hyperparameter space\n",
            "[2024-06-16T00:06:59.601637][GENERATOR][INFO]Successfully sampled '3' jobs, they will soon be submitted to the execution target.\n",
            "[2024-06-16T00:06:59.8316487Z][SCHEDULER][INFO]Scheduling job, id='dynamic_turtle_j8xh572jcq_2' \n",
            "[2024-06-16T00:06:59.8302900Z][SCHEDULER][INFO]Scheduling job, id='dynamic_turtle_j8xh572jcq_1' \n",
            "[2024-06-16T00:07:00.1904889Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dynamic_turtle_j8xh572jcq_1' \n",
            "[2024-06-16T00:07:00.3983533Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dynamic_turtle_j8xh572jcq_2' \n",
            "[2024-06-16T00:07:07.3324871Z][SCHEDULER][INFO]Scheduling job, id='dynamic_turtle_j8xh572jcq_0' \n",
            "[2024-06-16T00:07:07.6152818Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dynamic_turtle_j8xh572jcq_0' \n",
            "[2024-06-16T00:08:28.133555][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
            "[2024-06-16T00:08:28.465921][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
            "[2024-06-16T00:08:37.8674146Z][SCHEDULER][INFO]Scheduling job, id='dynamic_turtle_j8xh572jcq_3' \n",
            "[2024-06-16T00:08:38.9554828Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dynamic_turtle_j8xh572jcq_3' \n",
            "[2024-06-16T00:08:58.173357][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
            "[2024-06-16T00:08:58.499851][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
            "[2024-06-16T00:08:58.6407349Z][SCHEDULER][INFO]Scheduling job, id='dynamic_turtle_j8xh572jcq_4' \n",
            "[2024-06-16T00:08:58.9281581Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dynamic_turtle_j8xh572jcq_4' \n",
            "[2024-06-16T00:09:58.249907][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\n",
            "[2024-06-16T00:09:58.6400320Z][SCHEDULER][INFO]Scheduling job, id='dynamic_turtle_j8xh572jcq_5' \n",
            "[2024-06-16T00:09:58.527090][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\n",
            "[2024-06-16T00:09:59.0043865Z][SCHEDULER][INFO]Successfully scheduled a job. Id='dynamic_turtle_j8xh572jcq_5' \n",
            "[2024-06-16T00:10:28.136199][GENERATOR][INFO]Max number of jobs '6' reached for experiment.\n",
            "[2024-06-16T00:10:28.302093][GENERATOR][INFO]All jobs generated.\n",
            "[2024-06-16T00:11:32.4421928Z][CONTROLLER][INFO]Changing Run Status from Running to Completed \n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: dynamic_turtle_j8xh572jcq\n",
            "Web View: https://ml.azure.com/runs/dynamic_turtle_j8xh572jcq?wsid=/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/workspaces/maycohortmlops\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create or update the sweep job\n",
        "returned_sweep_job = ml_client.create_or_update(sweep_job) \n",
        "# stream the output and wait until the job is finished\n",
        "ml_client.jobs.stream(returned_sweep_job.name)\n",
        "# refresh the latest status of the job after streaming\n",
        "returned_sweep_job = ml_client.jobs.get(name=returned_sweep_job.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Extract the run that gave best modeling results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1718496729479
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Model\n",
        "if returned_sweep_job.status == \"Completed\":\n",
        "    # First let us get the run which gave us the best result\n",
        "    best_run = returned_sweep_job.properties[\"best_child_run_id\"]\n",
        "    # lets get the model from this run\n",
        "    model = Model(\n",
        "        # the script stores the model as \"best_model\"\n",
        "        path=\"azureml://jobs/{}/outputs/artifacts/paths/gbr-adv-sales-predictor/\".format(\n",
        "            best_run\n",
        "        ),\n",
        "        name=\"sales-predictor_best_model\",\n",
        "        description=\"Model created for sales prediction\",\n",
        "        type=\"custom_model\",\n",
        "    )\n",
        "else:\n",
        "    print(\n",
        "        \"Sweep job status: {}. Please wait until it completes\".format(\n",
        "            returned_sweep_job.status\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Register the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1718496730050
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "registered_model = ml_client.models.create_or_update(model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Configure an Endpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1718496824046
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from azure.ai.ml.entities import (\n",
        "    ManagedOnlineEndpoint,\n",
        "    ManagedOnlineDeployment,\n",
        "    Model,\n",
        "    Environment,\n",
        "    CodeConfiguration,\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1718496827712
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Importing the required modules\n",
        "import random\n",
        "import string\n",
        "# Creating a unique endpoint name by including a random suffix\n",
        "# Defining a list of allowed characters for the endpoint suffix\n",
        "allowed_chars = string.ascii_lowercase + string.digits\n",
        "# Generating a random 5-character suffix for the endpoint name by choosing\n",
        "# characters randomly from the list of allowed characters\n",
        "endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
        "# Creating the final endpoint name by concatenating a prefix string\n",
        "# with the generated suffix string\n",
        "endpoint_name = \"sales-endpoint-\" + endpoint_suffix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create an Endpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Online endpoints are endpoints that are used for online (real-time) inferencing. Online endpoints contain deployments that are ready to receive data from clients and can send responses back in real time.\n",
        "\n",
        "To create an online endpoint we will use ManagedOnlineEndpoint. This class allows user to configure the following key aspects such as name,auth_mode,identity,etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1718496831120
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=endpoint_name,  \n",
        "    # Name of the endpoint, should be unique within your deployment\n",
        "    description=\"An online endpoint serving an MLflow model\",\n",
        "    # A string describing the purpose of the endpoint\n",
        "    auth_mode=\"key\",\n",
        "    # Authentication mode to use for the endpoint (in this case, using an API key)\n",
        "    tags={\"foo\": \"bar\"},\n",
        "    # A dictionary of key-value pairs that can be used to tag the endpoint\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "This command will start the endpoint creation and return a confirmation response while the endpoint creation continues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1718496928807
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ManagedOnlineEndpoint({'public_network_access': 'Enabled', 'provisioning_state': 'Succeeded', 'scoring_uri': 'https://sales-endpoint-ix2q3.eastus.inference.ml.azure.com/score', 'openapi_uri': 'https://sales-endpoint-ix2q3.eastus.inference.ml.azure.com/swagger.json', 'name': 'sales-endpoint-ix2q3', 'description': 'An online endpoint serving an MLflow model', 'tags': {'foo': 'bar'}, 'properties': {'azureml.onlineendpointid': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourcegroups/tasnim_rg/providers/microsoft.machinelearningservices/workspaces/maycohortmlops/onlineendpoints/sales-endpoint-ix2q3', 'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/oeidp:306407ff-927a-47c9-8127-fd0067a9a4f0:24356ed1-4e95-403c-83f9-46b889dfeea9?api-version=2022-02-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/onlineEndpoints/sales-endpoint-ix2q3', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurekernelmlops2024/code/Users/niger.tasnim21/Milestoneproject1', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fd89c4f0e20>, 'auth_mode': 'key', 'location': 'eastus', 'identity': <azure.ai.ml.entities._credentials.IdentityConfiguration object at 0x7fd89c4f0a60>, 'traffic': {}, 'mirror_traffic': {}, 'kind': 'Managed'})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_endpoints.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Create a deployment script to perform model deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing ./src/score.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile {train_src_dir}/score.py\n",
        "# Import necessary libraries and modules\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "import mlflow\n",
        "from io import StringIO\n",
        "from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
        "######################LOGGER#####################\n",
        "# Set up Azure logging\n",
        "import logging\n",
        "from logging import Logger\n",
        "from opencensus.ext.azure.log_exporter import AzureLogHandler\n",
        "# Connect to Application Insights and set logging level to INFO\n",
        "application_insights_connection_string= 'InstrumentationKey=27c708c1-110c-494e-9321-e1d7095c5298;IngestionEndpoint=https://eastus-8.in.applicationinsights.azure.com/;LiveEndpoint=https://eastus.livediagnostics.monitor.azure.com/;ApplicationId=926eefd9-84d4-48e6-b0b4-9175bb4bbb28'\n",
        "handler = AzureLogHandler(\n",
        "connection_string=application_insights_connection_string)\n",
        "logger = logging.getLogger()\n",
        "logger.addHandler(handler)\n",
        "logger.setLevel(logging.INFO)\n",
        "####################################################\n",
        "# Define the init() function to load the MLflow model\n",
        "def init():\n",
        "    global model\n",
        "    global input_schema\n",
        "    # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
        "    # models, this is generally \"mlflow-model\"\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"gbr-adv-sales-predictor\")\n",
        "    model = mlflow.pyfunc.load_model(model_path)\n",
        "    input_schema = model.metadata.get_input_schema()\n",
        "# Define the run() function to make predictions using the loaded model\n",
        "def run(raw_data):\n",
        "    # Parse input data\n",
        "    json_data = json.loads(raw_data)\n",
        "    if \"input_data\" not in json_data.keys():\n",
        "        raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
        "    serving_input = json.dumps(json_data[\"input_data\"])\n",
        "    data = infer_and_parse_json_input(serving_input, input_schema)\n",
        "    # Make predictions\n",
        "    predictions = model.predict(data)\n",
        "    # Log the input data and predictions to Azure\n",
        "    logger.info(\"Data:{0},Predictions:{1}\".format(str(data),str(predictions)))\n",
        "    # Convert predictions to JSON format and return\n",
        "    result = StringIO()\n",
        "    predictions_to_json(predictions, result)\n",
        "    return result.getvalue()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Configure the deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1718497263591
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create a new deployment with name \"blue\"\n",
        "blue_deployment = ManagedOnlineDeployment(\n",
        "    name=\"blue\",\n",
        "    # Use the previously generated endpoint name\n",
        "    endpoint_name=endpoint_name,\n",
        "    # Use the registered model\n",
        "    model=registered_model,\n",
        "    # Use the latest environment \n",
        "    environment=\"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu@latest\",\n",
        "    # Use the code in the \"./src\" directory and the \"score.py\" script\n",
        "    code_configuration=CodeConfiguration(\n",
        "        code=\"./src\", scoring_script=\"score.py\"\n",
        "    ),\n",
        "    # Use a single instance of type \"Standard_E2s_v3\"\n",
        "    instance_type=\"Standard_E2s_v3\",\n",
        "    instance_count=1,\n",
        "    # Enable Application Insights for the deployment\n",
        "    app_insights_enabled=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1718497649970
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint sales-endpoint-ix2q3 exists\n",
            "\u001b[32mUploading src (0.01 MBs): 100%|██████████| 5266/5266 [00:00<00:00, 23865.83it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".........................................................................."
          ]
        },
        {
          "data": {
            "text/plain": [
              "ManagedOnlineDeployment({'private_network_connection': None, 'provisioning_state': 'Succeeded', 'endpoint_name': 'sales-endpoint-ix2q3', 'type': 'Managed', 'name': 'blue', 'description': None, 'tags': {}, 'properties': {'AzureAsyncOperationUri': 'https://management.azure.com/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/providers/Microsoft.MachineLearningServices/locations/eastus/mfeOperationsStatus/odidp:306407ff-927a-47c9-8127-fd0067a9a4f0:4468447f-608f-4953-90cd-73d5f387fd59?api-version=2023-04-01-preview'}, 'print_as_yaml': True, 'id': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/onlineEndpoints/sales-endpoint-ix2q3/deployments/blue', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurekernelmlops2024/code/Users/niger.tasnim21/Milestoneproject1', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fd89c4f1f30>, 'model': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/models/sales-predictor_best_model/versions/1', 'code_configuration': {'code': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/codes/e129a5f3-5c4d-4383-ae69-dbe7f093f7a3/versions/1'}, 'environment': '/subscriptions/4322d79c-475f-471d-bd6d-52528e4d32ee/resourceGroups/tasnim_rg/providers/Microsoft.MachineLearningServices/workspaces/maycohortmlops/environments/AzureML-sklearn-1.0-ubuntu20.04-py38-cpu/versions/36', 'environment_variables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE', 'AML_APP_INSIGHTS_KEY': '27c708c1-110c-494e-9321-e1d7095c5298', 'AML_APP_INSIGHTS_ENDPOINT': 'https://dc.services.visualstudio.com/v2/track', 'AML_APP_INSIGHTS_ENABLED': 'true', 'AZUREML_MODEL_DIR': '/var/azureml-app/azureml-models/sales-predictor_best_model/1', 'AZUREML_ENTRY_SCRIPT': 'score.py', 'AML_APP_ROOT': '/var/azureml-app/src'}, 'app_insights_enabled': True, 'scale_settings': <azure.ai.ml.entities._deployment.scale_settings.DefaultScaleSettings object at 0x7fd89c4f2710>, 'request_settings': <azure.ai.ml.entities._deployment.deployment_settings.OnlineRequestSettings object at 0x7fd89c4f2620>, 'liveness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fd89c4f25f0>, 'readiness_probe': <azure.ai.ml.entities._deployment.deployment_settings.ProbeSettings object at 0x7fd89c4f2140>, 'instance_count': 1, 'arm_type': 'online_deployment', 'model_mount_path': None, 'instance_type': 'Standard_E2s_v3', 'data_collector': None, 'egress_public_network_access': 'Enabled'})"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.online_deployments.begin_create_or_update(blue_deployment).result()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Delete the Endpoint\n",
        "\n",
        "**Important!** An Endpoint is a LIVE node which is always running, ready to process & predict to give you output. So unless you are making real-time predictions on streaming data, delete your endpoints after use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1718498421990
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<azure.core.polling._poller.LROPoller at 0x7fd89c453d90>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "........................................................................"
          ]
        }
      ],
      "source": [
        "ml_client.online_endpoints.begin_delete(name=endpoint_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### "
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
